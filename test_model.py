#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ¨¡å‹è°ƒç”¨è„šæœ¬
ç”¨äºæµ‹è¯•LLMæœåŠ¡çš„å›¾ç‰‡è§£æåŠŸèƒ½
"""

import asyncio
import base64
import json
import logging
import os
import sys
from pathlib import Path
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from backend.services.llm_service import LLMService
from backend.models.schemas import LLMProvider
from backend.config.settings import settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ModelTester:
    """
    æ¨¡å‹æµ‹è¯•ç±»
    ç”¨äºæµ‹è¯•ä¸åŒLLMæä¾›å•†çš„å›¾ç‰‡è§£æåŠŸèƒ½
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.llm_service = LLMService()
        
    def encode_image_to_base64(self, image_path: str) -> str:
        """
        å°†å›¾ç‰‡ç¼–ç ä¸ºbase64æ ¼å¼
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            
        Returns:
            str: base64ç¼–ç çš„å›¾ç‰‡æ•°æ®
        """
        try:
            with open(image_path, "rb") as image_file:
                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
                logger.info(f"å›¾ç‰‡ç¼–ç æˆåŠŸ: {image_path}")
                return encoded_string
        except Exception as e:
            logger.error(f"å›¾ç‰‡ç¼–ç å¤±è´¥: {str(e)}")
            raise
    
    async def test_openai_api(self, image_path: str, custom_prompt: Optional[str] = None) -> dict:
        """
        æµ‹è¯•OpenAI APIè°ƒç”¨
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            
        Returns:
            dict: APIå“åº”ç»“æœ
        """
        try:
            logger.info("å¼€å§‹æµ‹è¯•OpenAI API...")
            
            # ç¼–ç å›¾ç‰‡
            image_base64 = self.encode_image_to_base64(image_path)
            
            # æ„å»ºæç¤ºè¯
            prompt = self.llm_service.build_prompt("test_image.png", custom_prompt)
            logger.info(f"ä½¿ç”¨æç¤ºè¯: {prompt}")
            
            # è°ƒç”¨API
            response = await self.llm_service.call_openai_api(image_base64, prompt)
            logger.info("OpenAI APIè°ƒç”¨æˆåŠŸ")
            
            return response
            
        except Exception as e:
            logger.error(f"OpenAI APIæµ‹è¯•å¤±è´¥: {str(e)}")
            raise
    
    async def test_qwen_api(self, image_path: str, custom_prompt: Optional[str] = None) -> dict:
        """
        æµ‹è¯•é€šä¹‰åƒé—®APIè°ƒç”¨
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            
        Returns:
            dict: APIå“åº”ç»“æœ
        """
        try:
            logger.info("å¼€å§‹æµ‹è¯•é€šä¹‰åƒé—®API...")
            
            # ç¼–ç å›¾ç‰‡
            image_base64 = self.encode_image_to_base64(image_path)
            
            # æ„å»ºæç¤ºè¯
            prompt = self.llm_service.build_prompt("test_image.png", custom_prompt)
            logger.info(f"ä½¿ç”¨æç¤ºè¯: {prompt}")
            
            # è°ƒç”¨API
            response = await self.llm_service.call_qwen_api(image_base64, prompt)
            logger.info("é€šä¹‰åƒé—®APIè°ƒç”¨æˆåŠŸ")
            
            return response
            
        except Exception as e:
            logger.error(f"é€šä¹‰åƒé—®APIæµ‹è¯•å¤±è´¥: {str(e)}")
            raise
    
    async def test_analyze_image(self, image_path: str, provider: LLMProvider, 
                                custom_prompt: Optional[str] = None) -> list:
        """
        æµ‹è¯•å®Œæ•´çš„å›¾ç‰‡åˆ†ææµç¨‹
        
        Args:
            image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
            provider: LLMæä¾›å•†
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            
        Returns:
            list: è¯†åˆ«å‡ºçš„é¢˜ç›®åˆ—è¡¨
        """
        try:
            logger.info(f"å¼€å§‹æµ‹è¯•å›¾ç‰‡åˆ†ææµç¨‹ï¼Œæä¾›å•†: {provider.value}")
            
            # è°ƒç”¨åˆ†ææ–¹æ³•
            questions = await self.llm_service.analyze_image(
                image_path=image_path,
                provider=provider,
                filename="test_image.png",
                page_number=1,
                custom_prompt=custom_prompt
            )
            
            logger.info(f"å›¾ç‰‡åˆ†æå®Œæˆï¼Œè¯†åˆ«å‡º {len(questions)} é“é¢˜ç›®")
            return questions
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡åˆ†ææµ‹è¯•å¤±è´¥: {str(e)}")
            raise
    
    def print_questions(self, questions: list):
        """
        æ‰“å°è¯†åˆ«å‡ºçš„é¢˜ç›®ä¿¡æ¯
        
        Args:
            questions: é¢˜ç›®åˆ—è¡¨
        """
        if not questions:
            print("\nâŒ æ²¡æœ‰è¯†åˆ«å‡ºä»»ä½•é¢˜ç›®")
            return
        
        print(f"\nâœ… æˆåŠŸè¯†åˆ«å‡º {len(questions)} é“é¢˜ç›®:")
        print("=" * 80)
        
        for i, question in enumerate(questions, 1):
            print(f"\nğŸ“ é¢˜ç›® {i}:")
            print(f"   ID: {question.id}")
            print(f"   é¡µç : {question.page_number}")
            print(f"   å†…å®¹: {question.content}")
            print(f"   éš¾åº¦: {question.difficulty.value if question.difficulty else 'æœªçŸ¥'}")
            print(f"   çŸ¥è¯†ç‚¹: {', '.join(question.knowledge_points) if question.knowledge_points else 'æ— '}")
            print(f"   ç­”æ¡ˆ: {question.answer if question.answer else 'æ— '}")
            print(f"   è§£é¢˜æ­¥éª¤: {', '.join(question.solution_steps) if question.solution_steps else 'æ— '}")
            print(f"   æ¥æº: {question.source}")
            print("-" * 40)
    
    def save_response_to_file(self, response: dict, filename: str):
        """
        ä¿å­˜APIå“åº”åˆ°æ–‡ä»¶
        
        Args:
            response: APIå“åº”æ•°æ®
            filename: ä¿å­˜çš„æ–‡ä»¶å
        """
        try:
            output_dir = Path("test_outputs")
            output_dir.mkdir(exist_ok=True)
            
            output_file = output_dir / filename
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(response, f, ensure_ascii=False, indent=2)
            
            logger.info(f"å“åº”å·²ä¿å­˜åˆ°: {output_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å“åº”å¤±è´¥: {str(e)}")

async def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    """
    print("ğŸš€ LLMæ¨¡å‹æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥é…ç½®
    print("\nğŸ“‹ é…ç½®æ£€æŸ¥:")
    print(f"   OpenAI API Key: {'âœ… å·²é…ç½®' if settings.openai_api_key else 'âŒ æœªé…ç½®'}")
    print(f"   é€šä¹‰åƒé—® API Key: {'âœ… å·²é…ç½®' if settings.qwen_api_key else 'âŒ æœªé…ç½®'}")
    print(f"   OpenAI Base URL: {settings.openai_base_url}")
    print(f"   é€šä¹‰åƒé—® Base URL: {settings.qwen_base_url}")
    
    # è·å–ç”¨æˆ·è¾“å…¥
    print("\nğŸ“ è¯·è¾“å…¥è¦æµ‹è¯•çš„å›¾ç‰‡è·¯å¾„:")
    image_path = input("å›¾ç‰‡è·¯å¾„: ").strip()
    
    if not image_path:
        print("âŒ å›¾ç‰‡è·¯å¾„ä¸èƒ½ä¸ºç©º")
        return
    
    if not os.path.exists(image_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    print("\nğŸ¯ è¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. æµ‹è¯•OpenAI API")
    print("2. æµ‹è¯•é€šä¹‰åƒé—®API")
    print("3. æµ‹è¯•å®Œæ•´å›¾ç‰‡åˆ†ææµç¨‹ (OpenAI)")
    print("4. æµ‹è¯•å®Œæ•´å›¾ç‰‡åˆ†ææµç¨‹ (é€šä¹‰åƒé—®)")
    print("5. æµ‹è¯•æ‰€æœ‰åŠŸèƒ½")
    
    choice = input("è¯·é€‰æ‹© (1-5): ").strip()
    
    # è·å–è‡ªå®šä¹‰æç¤ºè¯
    print("\nğŸ’¬ è‡ªå®šä¹‰æç¤ºè¯ (å¯é€‰ï¼Œç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤):")
    custom_prompt = input("æç¤ºè¯: ").strip() or None
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = ModelTester()
    
    try:
        if choice == "1":
            # æµ‹è¯•OpenAI API
            if not settings.openai_api_key:
                print("âŒ OpenAI API Keyæœªé…ç½®")
                return
            
            response = await tester.test_openai_api(image_path, custom_prompt)
            print("\nğŸ“„ OpenAI APIå“åº”:")
            print(json.dumps(response, ensure_ascii=False, indent=2))
            tester.save_response_to_file(response, "openai_response.json")
            
        elif choice == "2":
            # æµ‹è¯•é€šä¹‰åƒé—®API
            if not settings.qwen_api_key:
                print("âŒ é€šä¹‰åƒé—®API Keyæœªé…ç½®")
                return
            
            response = await tester.test_qwen_api(image_path, custom_prompt)
            print("\nğŸ“„ é€šä¹‰åƒé—®APIå“åº”:")
            print(json.dumps(response, ensure_ascii=False, indent=2))
            tester.save_response_to_file(response, "qwen_response.json")
            
        elif choice == "3":
            # æµ‹è¯•OpenAIå®Œæ•´æµç¨‹
            if not settings.openai_api_key:
                print("âŒ OpenAI API Keyæœªé…ç½®")
                return
            
            questions = await tester.test_analyze_image(image_path, LLMProvider.OPENAI, custom_prompt)
            tester.print_questions(questions)
            
        elif choice == "4":
            # æµ‹è¯•é€šä¹‰åƒé—®å®Œæ•´æµç¨‹
            if not settings.qwen_api_key:
                print("âŒ é€šä¹‰åƒé—®API Keyæœªé…ç½®")
                return
            
            questions = await tester.test_analyze_image(image_path, LLMProvider.QWEN, custom_prompt)
            tester.print_questions(questions)
            
        elif choice == "5":
            # æµ‹è¯•æ‰€æœ‰åŠŸèƒ½
            print("\nğŸ”„ å¼€å§‹å…¨é¢æµ‹è¯•...")
            
            if settings.openai_api_key:
                print("\n--- OpenAIæµ‹è¯• ---")
                try:
                    questions = await tester.test_analyze_image(image_path, LLMProvider.OPENAI, custom_prompt)
                    print(f"OpenAIè¯†åˆ«ç»“æœ: {len(questions)} é“é¢˜ç›®")
                    tester.print_questions(questions)
                except Exception as e:
                    print(f"OpenAIæµ‹è¯•å¤±è´¥: {str(e)}")
            
            if settings.qwen_api_key:
                print("\n--- é€šä¹‰åƒé—®æµ‹è¯• ---")
                try:
                    questions = await tester.test_analyze_image(image_path, LLMProvider.QWEN, custom_prompt)
                    print(f"é€šä¹‰åƒé—®è¯†åˆ«ç»“æœ: {len(questions)} é“é¢˜ç›®")
                    tester.print_questions(questions)
                except Exception as e:
                    print(f"é€šä¹‰åƒé—®æµ‹è¯•å¤±è´¥: {str(e)}")
        
        else:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©")
            
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())